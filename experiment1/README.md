# Experiment 1: ZÃ¡kladnÃ­ RAG systÃ©m

Tento experiment pÅ™edstavuje **zÃ¡kladnÃ­ verzi RAG (Retrieval-Augmented Generation) systÃ©mu**, kterÃ½ kombinuje vyhledÃ¡vÃ¡nÃ­ relevantnÃ­ch informacÃ­ a jejich nÃ¡slednÃ© vyuÅ¾itÃ­ k generovÃ¡nÃ­ odpovÄ›dÃ­ pomocÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM).
## ğŸ§© Architektura systÃ©mu
Architektura se sklÃ¡dÃ¡ ze tÅ™Ã­ hlavnÃ­ch komponent:

1. **IndexovÃ¡nÃ­**  
   - ZÃ­skÃ¡vÃ¡nÃ­ dat z webovÃ½ch strÃ¡nek pomocÃ­ `BeautifulSoup` a `requests`
   - ÄŒiÅ¡tÄ›nÃ­ dat (odstranÄ›nÃ­ HTML tagÅ¯, prÃ¡zdnÃ½ch znakÅ¯, speciÃ¡lnÃ­ch symbolÅ¯)
   - RozdÄ›lenÃ­ textu na ÄÃ¡sti (`chunking`) s parametry `chunk_size` a `chunk_overlap`
   - VytvoÅ™enÃ­ vektorovÃ½ch reprezentacÃ­ pomocÃ­ embedding modelu `text-embedding-ada-002`
   - UloÅ¾enÃ­ embeddingÅ¯ do vektorovÃ© databÃ¡ze Pinecone

2. **Retriever**  
   - UÅ¾ivatelskÃ½ dotaz je pÅ™eveden do vektorovÃ© podoby
   - ProhledÃ¡vÃ¡ se databÃ¡ze embeddingÅ¯ pro nalezenÃ­ nejrelevantnÄ›jÅ¡Ã­ch textovÃ½ch segmentÅ¯ (`Top-k`)
   - PouÅ¾itÃ© skÃ³rovÃ¡nÃ­ na zÃ¡kladÄ› kosinovÃ© podobnosti

3. **GenerÃ¡tor**  
   - ZÃ­skanÃ© textovÃ© segmenty a uÅ¾ivatelskÃ½ dotaz jsou pÅ™edÃ¡ny modelu `gpt-3.5-turbo`
   - Model vygeneruje odpovÄ›Ä, kterÃ¡ je vrÃ¡cena uÅ¾ivateli

Tato zÃ¡kladnÃ­ architektura slouÅ¾Ã­ jako prvnÃ­ krok k experimentÅ¯m s optimalizacÃ­ vyhledÃ¡vÃ¡nÃ­ a generovÃ¡nÃ­ odpovÄ›dÃ­ pomocÃ­ RAG modelÅ¯:

![Architecture Experiment 1](./arch_exp1.png)


## ğŸ—‚ï¸ Struktura kÃ³du

- `indexing.py` â€“ Tento skript slouÅ¾Ã­ pro pÅ™Ã­pravu dat do vektorovÃ© databÃ¡ze.  
  ProvÃ¡dÃ­:
  - naÄtenÃ­ a extrakci textovÃ©ho obsahu z webovÃ½ch strÃ¡nek (pomocÃ­ knihovny `BeautifulSoup` a `requests`),
  - ÄiÅ¡tÄ›nÃ­ textu od HTML tagÅ¯ a nadbyteÄnÃ½ch znakÅ¯ (`strip()`, `replace()`, regulÃ¡rnÃ­ vÃ½razy),
  - rozdÄ›lenÃ­ textu na ÄÃ¡sti (chunking),
  - vÃ½poÄet embeddingÅ¯ pomocÃ­ modelu `text-embedding-ada-002`,
  - uloÅ¾enÃ­ vÃ½slednÃ½ch vektorÅ¯ do databÃ¡ze Pinecone.

- `main1.py` â€“ HlavnÃ­ skript pro bÄ›h chatbotu v rÃ¡mci experimentu 1.  
  Obsahuje rozhranÃ­ ve Streamlit, logiku retrieveru a generovÃ¡nÃ­ odpovÄ›dÃ­ pomocÃ­ OpenAI API.  
  Tento skript je urÄen pro testovÃ¡nÃ­ zÃ¡kladnÃ­ RAG architektury popsanÃ© vÃ½Å¡e.

- `evaluation1.py` â€“ PomocnÃ½ skript pro vyhodnocenÃ­ vÃ½sledkÅ¯.  
  Po spuÅ¡tÄ›nÃ­ analyzuje odpovÄ›di generovanÃ© chatbotem a vypoÄÃ­tÃ¡ klÃ­ÄovÃ© metriky, jako jsou:
  - celkovÃ¡ spotÅ™eba tokenÅ¯,
  - dÃ©lka odpovÄ›dÃ­,
  - prÅ¯mÄ›rnÃ© skÃ³re podobnosti s pouÅ¾itÃ½m kontextem.
 
## ğŸ“ VÃ½stupy

- VÃ½stupy experimentu (odpovÄ›di) jsou uklÃ¡dÃ¡ny do souboru `outputs1.txt`

ğŸ“Š Vizualizace vÃ½sledkÅ¯ je zobrazena v tabulce nÃ­Å¾e.  

## âš™ï¸ Parametry testovanÃ½ch verzÃ­

V rÃ¡mci testovÃ¡nÃ­ bylo provedeno 6 variant experimentu (1aâ€“1f), kterÃ© se liÅ¡Ã­ velikostÃ­ segmentÅ¯ a mÃ­rou pÅ™ekryvu:

| Verze | Chunk size | Overlap | Top-k | PÅ™esnost (ACC %) | Tokeny |
|-------|------------|---------|-------|------------------|--------|
| 1a    | 256        | 10      | 10    | 50               | 69 481 |
| 1b    | 370        | 20      | 7     | 52               | 67 113 |
| 1c    | 512        | 40      | 5     | 50               | 63 216 |
| 1d    | 640        | 60      | 4     | 48               | 60 763 |
| 1e    | 768        | 80      | 3     | 43               | 52 264 |
| 1f    | 1024       | 100     | 2     | 45               | 46 489 |

ğŸ§  VÃ½sledek ukÃ¡zal, Å¾e **menÅ¡Ã­ textovÃ© segmenty** s vyÅ¡Å¡Ã­m poÄtem vrÃ¡cenÃ½ch vÃ½sledkÅ¯ (**Top-k**) vedou k **vyÅ¡Å¡Ã­ pÅ™esnosti**, zatÃ­mco **delÅ¡Ã­ segmenty** sniÅ¾ujÃ­ **spotÅ™ebu tokenÅ¯**, ale zÃ¡roveÅˆ i **kvalitu odpovÄ›dÃ­**.

ğŸ“Œ Tento experiment pomohl lÃ©pe se zorientovat v tom, **jakÃ¡ dÃ©lka textovÃ½ch segmentÅ¯ je nejvhodnÄ›jÅ¡Ã­** pro dalÅ¡Ã­ testovÃ¡nÃ­ â€“ tedy **kde leÅ¾Ã­ rovnovÃ¡ha mezi pÅ™esnostÃ­ a efektivitou** systÃ©mu.


## ğŸ” ShrnutÃ­ problÃ©mu v experimentu 1

Experiment pracuje s reÃ¡lnÃ½mi dotazy z pÅ™Ã­loh A, B a C diplomovÃ© prÃ¡ce. HodnocenÃ­ odpovÄ›dÃ­ bylo provedeno manuÃ¡lnÄ› s ohledem na oÄekÃ¡vanÃ© odpovÄ›di.

- V nÄ›kterÃ½ch pÅ™Ã­padech byly odpovÄ›di nepÅ™esnÃ©, protoÅ¾e generÃ¡tor nedostal vÅ¡echny dÅ¯leÅ¾itÃ© informace â€“ ty byly rozptÃ½lenÃ© v nÄ›kolika segmentech, nebo nebyly sprÃ¡vnÄ› vybrÃ¡ny retrieverem.

- **Studenti Äasto pouÅ¾Ã­vajÃ­ bÄ›Å¾nÃ½ hovorovÃ½ jazyk** (napÅ™. *â€jak se dostanu na magistraâ€œ*), zatÃ­mco **webovÃ© strÃ¡nky pouÅ¾Ã­vajÃ­ formÃ¡lnÃ­ formulace** (napÅ™. *â€podmÃ­nky pro pÅ™ijetÃ­ do navazujÃ­cÃ­ho magisterskÃ©ho studiaâ€œ*).  
  **Retriever v zÃ¡kladnÃ­ verzi nebyl dostateÄnÄ› robustnÃ­**, aby tyto **strukturÃ¡lnÃ­ nebo sÃ©mantickÃ© rozdÃ­ly** rozpoznal, coÅ¾ vedlo ke **ztrÃ¡tÄ› relevance** pÅ™i vÃ½bÄ›ru textÅ¯.
-  PÅ™i dÄ›lenÃ­ textu na Ãºseky Äasto vznikaly velmi krÃ¡tkÃ© "zbytky" na konci dokumentÅ¯, kterÃ© neobsahovaly Å¾Ã¡dnÃ© dÅ¯leÅ¾itÃ© informace.  
  Embedding model jim pÅ™esto pÅ™iÅ™adil vektory, kterÃ© byly **nesprÃ¡vnÄ› hodnoceny jako velmi podobnÃ© uÅ¾ivatelskÃ©mu dotazu**, protoÅ¾e chybÄ›la sÃ©mantickÃ¡ vÃ½povÄ›Ä. ğŸ¤·â€â™‚ï¸  Retriever nÃ¡slednÄ› vybÃ­ral tyto prÃ¡zdnÃ© nebo nerelevantnÃ­ texty, protoÅ¾e je povaÅ¾oval za dÅ¯leÅ¾itÃ©. Pokud se v databÃ¡zi nenachÃ¡zel relevantnÃ­ kontext, systÃ©m i pÅ™esto zpracoval tyto nerelevantnÃ­ Ãºseky â€“ a zbyteÄnÄ› tak spotÅ™eboval tokeny pÅ™i generovÃ¡nÃ­ odpovÄ›di.




