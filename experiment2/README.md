# Experiment 2: ZlepÅ¡enÃ¡ segmentace a tematickÃ¡ optimalizace

Tento experiment navazuje na zÃ¡kladnÃ­ verzi RAG systÃ©mu a zamÄ›Å™uje se na **optimalizaci pÅ™Ã­pravy dat** a **vÃ½bÄ›ru relevantnÃ­ho kontextu** tak, aby byly odstranÄ›ny slabiny identifikovanÃ© v experimentu 1.

---

## ğŸ§© Architektura systÃ©mu

Architektura je stÃ¡le tÅ™Ã­komponentnÃ­ (IndexovÃ¡nÃ­, Retriever, GenerÃ¡tor), ale zÃ¡sadnÃ­ zmÄ›ny byly provedeny v pÅ™Ã­pravÄ› a struktuÅ™e dat:

### **IndexovÃ¡nÃ­**
- Data jsou z webovÃ½ch strÃ¡nek zÃ­skÃ¡vÃ¡na a ÄiÅ¡tÄ›na stejnÄ› jako v experimentu 1, ale mÃ­sto mechanickÃ©ho dÄ›lenÃ­ na stejnÄ› dlouhÃ© ÄÃ¡sti jsou novÄ› tvoÅ™eny **koherentnÃ­ tematickÃ© bloky**.
- TematickÃ© bloky byly v tomto experimentu **vytvoÅ™eny ruÄnÄ›** na zÃ¡kladÄ› tematickÃ© podobnosti a experimentÃ¡lnÃ­ analÃ½zy.  
  KaÅ¾dÃ½ blok obsahuje vÅ¡echny informace k jednomu tÃ©matu (napÅ™. kompletnÃ­ podmÃ­nky pÅ™ijetÃ­ na magisterskÃ© studium).
- **V reÃ¡lnÃ©m provozu** by byly bloky **automaticky generovÃ¡ny a aktualizovÃ¡ny pÅ™Ã­mo z databÃ¡ze znalostÃ­** (napÅ™. pomocÃ­ systÃ©mu Aphinit).
- Embeddingy jsou vytvÃ¡Å™eny pomocÃ­ modelu `text-embedding-ada-002` a uloÅ¾eny do Pinecone.
- UkÃ¡zka tematickÃ©ho seskupenÃ­ textÅ¯ je k dispozici v souboru **`text_pairs2.txt`** (ve formÃ¡tu JSON).

### **Retriever**
- UÅ¾ivatelskÃ½ dotaz je opÄ›t pÅ™eveden na embedding.
- VyhledÃ¡vÃ¡nÃ­ probÃ­hÃ¡ nad tematicky celistvÃ½mi bloky, coÅ¾ **sniÅ¾uje riziko vybrÃ¡nÃ­ irelevantnÃ­ch zbytkovÃ½ch textÅ¯**.
- SkÃ³rovÃ¡nÃ­ a Top-k jsou optimalizovanÃ© dle vÃ½sledkÅ¯ experimentu 1.

### **GenerÃ¡tor**
- OdpovÄ›di jsou generovÃ¡ny na zÃ¡kladÄ› vÃ½znamovÄ› ucelenÄ›jÅ¡Ã­ho kontextu (vÄ›tÅ¡Ã­ tematickÃ½ blok).
- PouÅ¾it je model `gpt-3.5-turbo` (OpenAI API).

---

## ğŸ—‚ï¸ Struktura kÃ³du

- **`indexing2.py`** â€“ Skript pro pokroÄilou pÅ™Ã­pravu dat do vektorovÃ© databÃ¡ze (seskupuje texty podle tÃ©mat, ÄistÃ­ je a uklÃ¡dÃ¡ tematickÃ© bloky do Pinecone).
- **`main2.py`** â€“ HlavnÃ­ skript pro bÄ›h chatbotu v rÃ¡mci experimentu 2 (vylepÅ¡enÃ½ retriever, Streamlit UI).
- **`evaluation2.py`** â€“ Skript pro vyhodnocenÃ­ vÃ½sledkÅ¯ (analyzuje pÅ™esnost, spotÅ™ebu tokenÅ¯ atd.).
- **`text_pairs2.txt`** â€“ UkÃ¡zka tematicky seskupenÃ½ch blokÅ¯ ve formÃ¡tu JSON. KaÅ¾dÃ½ zÃ¡znam pÅ™edstavuje ucelenÃ½ tematickÃ½ blok.

---

## ğŸ“ VÃ½stupy

- VÃ½stupy generovanÃ½ch odpovÄ›dÃ­ jsou uklÃ¡dÃ¡ny do souboru `outputs2.txt`.
- VÃ½sledky experimentu jsou podrobnÄ› analyzovÃ¡ny v diplomovÃ© prÃ¡ci a shrnuty v tabulkÃ¡ch a grafech.

---

## âš™ï¸ Parametry a vÃ½sledky testovanÃ½ch verzÃ­

V tomto experimentu byly testovÃ¡ny rÅ¯znÃ© strategie tematickÃ©ho seskupenÃ­ a nastavenÃ­ parametru Top-k.

| Verze | Typ segmentace        | Top-k | PÅ™esnost (ACC %) | Tokeny |
|-------|----------------------|-------|------------------|--------|
| 2a    | TematickÃ© bloky      | 3     | 89               | 39 412 |
| 2b    | TematickÃ© bloky      | 2     | 91               | 33 856 |
| 2c    | TematickÃ© bloky      | 1     | 85               | 28 412 |

ğŸ§  **DÃ­ky tematickÃ©mu seskupenÃ­ textÅ¯ a optimalizaci retrieveru doÅ¡lo k vÃ½raznÃ©mu zvÃ½Å¡enÃ­ pÅ™esnosti i snÃ­Å¾enÃ­ spotÅ™eby tokenÅ¯ oproti experimentu 1.**

---

## ğŸ” Motivace pro experiment 2

ZÃ¡sadnÃ­ nedostatky experimentu 1, kterÃ© tento experiment Å™eÅ¡Ã­:
- OdpovÄ›di byly Äasto nepÅ™esnÃ©, protoÅ¾e klÃ­ÄovÃ© informace byly rozptÃ½leny v nÄ›kolika krÃ¡tkÃ½ch ÃºsecÃ­ch a generÃ¡tor je neobdrÅ¾el pohromadÄ›.
- **Studenti Äasto pouÅ¾Ã­vajÃ­ bÄ›Å¾nÃ½ hovorovÃ½ jazyk** (napÅ™. â€jak se dostanu na magistraâ€œ), zatÃ­mco **webovÃ© strÃ¡nky pouÅ¾Ã­vajÃ­ formÃ¡lnÃ­ formulace** (napÅ™. â€podmÃ­nky pro pÅ™ijetÃ­ do navazujÃ­cÃ­ho magisterskÃ©ho studiaâ€œ).  
  **Retriever v zÃ¡kladnÃ­ verzi nebyl dostateÄnÄ› robustnÃ­**, aby tyto **strukturÃ¡lnÃ­ nebo sÃ©mantickÃ© rozdÃ­ly** rozpoznal, coÅ¾ vedlo ke **ztrÃ¡tÄ› relevance** pÅ™i vÃ½bÄ›ru textÅ¯.
- ğŸ§© **ZbytkovÃ© texty bez obsahu zpÅ¯sobovaly chyby pÅ™i vyhledÃ¡vÃ¡nÃ­**  
  PÅ™i dÄ›lenÃ­ textu na Ãºseky Äasto vznikaly velmi krÃ¡tkÃ© "zbytky" na konci dokumentÅ¯, kterÃ© neobsahovaly Å¾Ã¡dnÃ© dÅ¯leÅ¾itÃ© informace.  
  Embedding model jim pÅ™esto pÅ™iÅ™adil vektory, kterÃ© byly nesprÃ¡vnÄ› hodnoceny jako velmi podobnÃ© uÅ¾ivatelskÃ©mu dotazu, protoÅ¾e chybÄ›la sÃ©mantickÃ¡ vÃ½povÄ›Ä.  
  ğŸ¤·â€â™‚ï¸ Retriever nÃ¡slednÄ› vybÃ­ral tyto prÃ¡zdnÃ© nebo nerelevantnÃ­ texty, protoÅ¾e je povaÅ¾oval za dÅ¯leÅ¾itÃ©. Pokud se v databÃ¡zi nenachÃ¡zel relevantnÃ­ kontext, systÃ©m i pÅ™esto zpracoval tyto nerelevantnÃ­ Ãºseky â€“ a zbyteÄnÄ› tak spotÅ™eboval tokeny pÅ™i generovÃ¡nÃ­ odpovÄ›di.

---

## ğŸ“Š Vizualizace vÃ½sledkÅ¯

Vizualizace vÃ½sledkÅ¯ experimentu je zobrazena v pÅ™iloÅ¾enÃ½ch tabulkÃ¡ch a grafech.  
PodrobnÃ½ rozbor naleznete v pÅ™Ã­sluÅ¡nÃ© kapitole diplomovÃ© prÃ¡ce.

---

**Tento experiment jasnÄ› ukazuje, Å¾e kvalitnÄ›jÅ¡Ã­ pÅ™Ã­prava dat a tematickÃ© seskupenÃ­ textÅ¯ vedou nejen k ÃºspoÅ™e nÃ¡kladÅ¯, ale zejmÃ©na ke zvÃ½Å¡enÃ­ kvality odpovÄ›dÃ­.**


<img width="492" alt="image" src="https://github.com/user-attachments/assets/7cddf2ce-222f-4f7e-9abb-9efa5dd75b04">


![image](https://github.com/user-attachments/assets/7aed2a35-2221-4380-a71c-8dda9d62555d)
